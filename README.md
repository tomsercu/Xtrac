Xtrac
=====

Introduction 
==
The goal of the Xtrac project is to generate a large unsupervised dataset of images by extracting frames from youtube videos.
We first generate search queries, use these queries to search youtube movies that are related to the object categories we are interested in.
We then use our processing scripts to detect shots of interest and discard the useless shots.

This project folder contains all scripts used to generate the dataset from the youtube search queries.

Folder and files structure 
==
The pipeline so far consists of a series of python scripts.
The pipeline is folder-based, and assumes following folders in your path (this should be parametrized in later versions):
+ *~/youtube* - Location where the youtube movies will be downloaded to, in mov or flv format
+ *~/cifar32_all* - Where the output of the ffmpeg frame extraction will arrive, a series of cropped and resized frames: the first frame of each shot after a transition is detected, followed by sampled frames at a parametrized framerate (eg 2 fps).
+ *~/cifar32_selected* - Where the frames are written that survived the first round of cheap filtering, organized per shot and frame within that shot.

Structure of scripts
==
+ *generate\_queries.py* manually generates the json file containing the subjects (eg the CIFAR10 classes), with each subject corresponding to multiple youtube queries.
+ *download.py* Reads the .json and subprocess youtube-dl to download the movies in the ~/youtube folder
+ *extract_frames_ffmpeg.py* subprocesses ffmpeg to do automatic cut detection and to dump out the starting frame of each shot, followed by a selection of frames from that shot, at a rate of eg 2 fps. This series of frames is used for the cheap filtering in the next step. The log file generated by ffmpeg (out.log) is parsed to organize the frames into shots they belong to. The shot-organized frame info is stored in the *info.pk* file.
+ *select_cheap.py* applies a cascade of filters to the shots and discards shots that are too short, that are too dark or too bright, shots that are too dynamic or too static, and shots that contain unnatural images (eg title frames)
+ *select_tracking.py* Will actually look at the original videos' shots that survived the first round of filtering and use tracking to determine if there is an interesting central object in the shot.

Dependencies
==
Python 2.7 with matplotlib, PIL
OpenCV 2 with python bindings
ffmpeg (>=1.2.1), needs the "scene" filter
youtube-dl
