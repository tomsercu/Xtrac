Xtrac
=====

Introduction 
==
The goal of the Xtrac project is to generate a large unsupervised dataset of images by extracting frames from youtube videos.
We first generate search queries, use these queries to search youtube movies that are related to the object categories we are interested in.
We then use the processing scripts to break the video into shots (with ffmpeg scene detection) and discard the useless shots.

This project folder contains all scripts used to generate the dataset from the youtube search queries.

Where are the files
==
+ /misc/vlgscratch2/FergusGroup/sercu/youtube2  The raw movies. The most recent .json file in this folder gives the search queries and associated ids (these are just ids you can use in  https://www.youtube.com/watch?v=**ID**
+ /misc/vlgscratch2/FergusGroup/sercu/thumbs  The thumbnails, 0.5 secoonds apart, Wx32 pixels.  These are used to do a quick selection to discard frames on brightness, staticness, unnatural images.
+ /misc/vlgscratch2/FergusGroup/sercu/frames  The shots that passed the quick selection get extracted at full framerate here, size Wx300. I didn't let this extraction complete to save space on vlgscratch.

All info about shots and selection is in .json files:
+ thumbs/subject/vidid/shots.json contains a list of shots in the video. Each shot has a list of frames/thumbs. Each thumb has a order number used in naming the thumb.
+ thumbs/subject/vidid/filtered.json is a dictionary: filter\_ids gives codes to different selection criteria, shots\_pass gives  contains a list with a selection code for each shot in the movie.
+ frames/subject/vidid/shots.json   is a list with shots in the movie, of the same length as the previous lists. [none, none] means the shot did not pass the selection and is not extracted here, [start, end] is the index of the frames in the frames/ directory.

To get an idea of what a movie looks like:

+ thumbs/subject/grid_VIDID.jpg    just to look at a sample of the thumbnails, without selection.
+ thumbs/subject/VIDID/filter_X.jpg   overview of the shots that are too X or if X=="pass" the shots that passed selection.

Pipeline
==
The pipeline is folder-based, and assumes following folders in your path (parametrized in conf.py):
+ *~/youtube* - Location where the youtube movies are downloaded, in mp4 or flv format
+ *~/thumbs* - The Wx32 thumbnails extracted from movie. The first frame of each shot after a transition is detected, followed by sampled frames at a framerate conf.thumbs.framerate.
+ *~/frames* - Where the frames are written that passed the first round of selection.

Structure of scripts
==
+ *download.py* Reads the query json and subprocesses youtube-dl to download the movies in the ~/youtube folder
+ *extract_frames_ffmpeg.py* subprocesses ffmpeg to do automatic shot detection and to dump out the starting frame of each shot, followed by a sample of frames from that shot, at a rate of eg 2 fps. This series of frames is used for the quick selection in the next step. The log file generated by ffmpeg (out.log) is parsed to organize the frames into shots they belong to. The shot-organized frame info is stored in the *shots.json* file.
+ *select_cheap.py* applies a cascade of selection filters to the shots and discards shots that are too short, that are too dark or too bright, shots that are too dynamic or too static, and shots that contain unnatural patches (patch of exactly the same pixel values)
+ *segmentation with optical flow*  too computationally expensive.

Dependencies
==
Python 2.7 with matplotlib, PIL
OpenCV 2 with python bindings
ffmpeg (>=1.2.1), needs the "scene" filter
youtube-dl
